llm:
  model_id: "llama3.2:3b" # Ollama model ID
  temperature: 0.7
  device: "auto" # "cpu", "cuda", or "auto"
  max_tokens: 3000

generation:
  n_valid_values: 10
  n_invalid_values: 2
